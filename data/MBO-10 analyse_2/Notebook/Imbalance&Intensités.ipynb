{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étude de l'imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_csv = glob.glob(os.path.join(\"/Volumes/T9/CSV_GOOGL_NASDAQ_PL\", \"*.csv\"))\n",
    "#files_csv = glob.glob(os.path.join(\"/Volumes/T9/filtrage_KHC/\", \"*.csv\"))\n",
    "imb = np.array([])\n",
    "price = np.array([])\n",
    "limite = 0\n",
    "for f in tqdm(files_csv):\n",
    "    df = pd.read_csv(f)\n",
    "    df = df[:-100]\n",
    "    imb = np.concatenate([imb, df['imbalance'].to_numpy()])\n",
    "    price = np.concatenate([price, df['Mean_price_diff'].to_numpy()])\n",
    "\n",
    "print(f\"A quel point c'est long: {len(imb)}\")\n",
    "# ATTENTION L'imbalance est moins l'imbalance et les mid price sont - les midprices, dcp ca chage rien au graphe mais a modif au cas ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_trie = np.argsort(imb)\n",
    "\n",
    "bounds = 0.85\n",
    "imb_trie = imb[indices_trie]\n",
    "price_trie = price[indices_trie]\n",
    "mask = (imb_trie >= -bounds)&(imb_trie <= bounds)\n",
    "imb_trie = imb_trie[mask]\n",
    "price_trie = price_trie[mask]\n",
    "group_size = 3500000\n",
    "\n",
    "imb_trie_groups = [imb_trie[i:i + group_size] for i in range(0, len(imb_trie), group_size)]\n",
    "price_trie_groups = [price_trie[i:i + group_size] for i in range(0, len(price_trie), group_size)]\n",
    "\n",
    "imb_trie_means = np.array([np.mean(group) for group in imb_trie_groups])\n",
    "price_trie_means = np.array([np.mean(group) for group in price_trie_groups])\n",
    "\n",
    "imb_trie_std = np.array([np.std(group)/np.sqrt(len(group)) for group in price_trie_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=imb_trie_means,y=price_trie_means + 1.96 * imb_trie_std,mode='lines',line=dict(width=0),name='Upper Bound',showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=imb_trie_means,y=price_trie_means - 1.96 * imb_trie_std,mode='lines',line=dict(width=0),fill='tonexty',fillcolor='blue',name='Intervalle de confiance à 95%',showlegend=True))\n",
    "fig.add_trace(go.Scatter(x=imb_trie_means,y=price_trie_means,mode='lines',name='Prix',line=dict(color='red'),showlegend=True))\n",
    "fig.update_layout(title='Imbalance non recentré',xaxis_title='imbalance',yaxis_title='delta_price',showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bins = 30\n",
    "counts, bin_edges = np.histogram(imb_trie, bins=nb_bins)\n",
    "bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=bin_centers,y=counts,mode='lines',name='Density Curve'))\n",
    "fig.update_layout(title=f\"Courbe de distribution de l'imbalance (tous event confondus)\",xaxis_title='imbalance',yaxis_title='number of events',showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_trade = np.array([])\n",
    "price_trade = np.array([])\n",
    "imb_add = np.array([])\n",
    "price_add = np.array([])\n",
    "imb_cancel = np.array([])\n",
    "price_cancel = np.array([])\n",
    "limite = 0\n",
    "for f in tqdm(files_csv):\n",
    "    df = pd.read_csv(f)\n",
    "    df = df[:-100]\n",
    "    df_trade = df[df['action'] == 'T']\n",
    "    df_cancel = df[df['action'] == 'C']\n",
    "    df_add = df[df['action'] == 'A']\n",
    "    imb_trade = np.concatenate([imb_trade, df_trade['imbalance'].to_numpy()])\n",
    "    price_trade = np.concatenate([price_trade, df_trade['Mean_price_diff'].to_numpy()])\n",
    "    imb_add = np.concatenate([imb_add, df_add['imbalance'].to_numpy()])\n",
    "    price_add = np.concatenate([price_add, df_add['Mean_price_diff'].to_numpy()])\n",
    "    imb_cancel = np.concatenate([imb_cancel, df_cancel['imbalance'].to_numpy()])\n",
    "    price_cancel = np.concatenate([price_cancel, df_cancel['Mean_price_diff'].to_numpy()])\n",
    "    \n",
    "imb_tot = [imb_trade,imb_add,imb_cancel]\n",
    "price_tot = [price_trade,price_add,price_cancel]\n",
    "\n",
    "print(f\"A quel point c'est long: {len(imb_trade)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu_imbalance_respec(imb_tot, price_tot, i , string, group_size, bound = 0.95):\n",
    "    indices_trie = np.argsort(imb_tot[i])\n",
    "    imb_trie = imb_tot[i][indices_trie]\n",
    "    price_trie = price_tot[i][indices_trie]\n",
    "    mask = (imb_trie >= -bound)&(imb_trie <= bound)\n",
    "    imb_trie = imb_trie[mask]\n",
    "    price_trie = price_trie[mask]\n",
    "    imb_trie_groups = [imb_trie[i:i+group_size] for i in range(0, len(imb_trie), group_size)]\n",
    "    price_trie_groups = [price_trie[i:i+group_size] for i in range(0, len(price_trie), group_size)]\n",
    "    imb_trie_means = np.array([np.mean(group) for group in imb_trie_groups])\n",
    "    price_trie_means = np.array([np.mean(group) for group in price_trie_groups])\n",
    "    imb_trie_std = np.array([np.std(group)/np.sqrt(len(group)) for group in price_trie_groups])\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=imb_trie_means,y=price_trie_means + 1.96 * imb_trie_std,mode='lines',line=dict(width=0),name='Upper Bound',showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=imb_trie_means,y=price_trie_means - 1.96 * imb_trie_std,mode='lines',line=dict(width=0),fill='tonexty',fillcolor='blue',name='Intervalle de confiance à 95%',showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=imb_trie_means,y=price_trie_means,mode='lines',name='Prix',line=dict(color='red'),showlegend=True))\n",
    "    fig.update_layout(title=f'Imbalance des {string}',xaxis_title='imbalance',yaxis_title='delta_price',showlegend=True)\n",
    "    fig.show()\n",
    "\n",
    "    nb_bins = 20\n",
    "    counts, bin_edges = np.histogram(imb_trie, bins=nb_bins)\n",
    "    bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=bin_centers,y=counts,mode='lines',name='Density Curve'))\n",
    "    fig.update_layout(title=f\"Courbe de distribution de l'imbalance des {string}\",xaxis_title='imbalance',yaxis_title='number of events',showlegend=False)\n",
    "    fig.show()\n",
    "\n",
    "def visu_event_vs_imbalance(imb_tot, price_tot, string, bound = 0.9):\n",
    "    fig = go.Figure()\n",
    "    nb_bins = 25\n",
    "    counts_tot = []\n",
    "    bins_centers_tot = []\n",
    "    for i in range (len(imb_tot)):\n",
    "        indices_trie = np.argsort(imb_tot[i])\n",
    "        imb_trie = imb_tot[i][indices_trie]\n",
    "        price_trie = price_tot[i][indices_trie]\n",
    "        mask = (imb_trie >= -bound)&(imb_trie <= bound)\n",
    "        imb_trie = imb_trie[mask]\n",
    "        price_trie = price_trie[mask]\n",
    "        counts, bin_edges = np.histogram(imb_trie, bins=nb_bins)\n",
    "        counts_tot.append(counts)\n",
    "        bins_centers_tot.append((bin_edges[:-1]+bin_edges[1:])/2)\n",
    "    counts_total = np.array(counts_tot[0])+np.array(counts_tot[1])+np.array(counts_tot[2])\n",
    "    for i in range (len(imb_tot)):\n",
    "        fig.add_trace(go.Scatter(x=bins_centers_tot[i],y=np.array(counts_tot[i])/counts_total,mode='lines',name=f'{string[i]}'))\n",
    "    fig.update_layout(title=f\"Courbes de distribution de l'imbalance (tous les event))\",xaxis_title='imbalance',yaxis_title=\"Probabilité de l'event\",showlegend=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_imbalance_respec(imb_tot, price_tot, 0 , 'trades', 100000)\n",
    "visu_imbalance_respec(imb_tot, price_tot, 1 , 'add', 1500000)\n",
    "visu_imbalance_respec(imb_tot, price_tot, 2 , 'cancel', 1500000)\n",
    "visu_event_vs_imbalance(imb_tot, price_tot, ['Trades', 'Cancel',' Add'], bound = .95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb = np.array([])\n",
    "intensity = np.array([])\n",
    "limite = 0\n",
    "for f in tqdm(files_csv):\n",
    "    df = pd.read_csv(f)\n",
    "    df = df[:-100]\n",
    "    imb = np.concatenate([imb, df['imbalance'].to_numpy()])\n",
    "    intensity = np.concatenate([intensity, df['time_diff'].to_numpy()])\n",
    "\n",
    "intensity = 1/np.array(intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_trie = np.argsort(imb)\n",
    "\n",
    "bounds = 0.95\n",
    "imb_trie = imb[indices_trie]\n",
    "intensity_trie = intensity[indices_trie]\n",
    "mask = (imb_trie >= -bounds)&(imb_trie <= bounds)\n",
    "imb_trie = imb_trie[mask]\n",
    "intensity_trie = intensity_trie[mask]\n",
    "group_size = 3000000\n",
    "\n",
    "imb_trie_groups = [imb_trie[i:i + group_size] for i in range(0, len(imb_trie), group_size)]\n",
    "intensity_trie_groups = [intensity_trie[i:i + group_size] for i in range(0, len(intensity_trie), group_size)]\n",
    "\n",
    "imb_trie_means = np.array([np.mean(group) for group in imb_trie_groups])\n",
    "intensity_trie_means = np.array([np.mean(group) for group in intensity_trie_groups])\n",
    "\n",
    "intensity_trie_std = np.array([np.std(group)/np.sqrt(len(group)) for group in intensity_trie_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=imb_trie_means,y=intensity_trie_means + 1.96 * intensity_trie_std,mode='lines',line=dict(width=0),name='Upper Bound',showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=imb_trie_means,y=intensity_trie_means - 1.96 * intensity_trie_std,mode='lines',line=dict(width=0),fill='tonexty',fillcolor='blue',name='Intervalle de confiance à 95%',showlegend=True))\n",
    "fig.add_trace(go.Scatter(x=imb_trie_means,y=intensity_trie_means,mode='lines',name='intensity',line=dict(color='red'),showlegend=True))\n",
    "fig.update_layout(title='Intensity (tous events confondus)',xaxis_title='imbalance',yaxis_title='Intensity',showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_trade = np.array([])\n",
    "intensity_trade = np.array([])\n",
    "imb_add = np.array([])\n",
    "intensity_add = np.array([])\n",
    "imb_cancel = np.array([])\n",
    "intensity_cancel = np.array([])\n",
    "limite = 0\n",
    "for f in tqdm(files_csv):\n",
    "    df = pd.read_csv(f)\n",
    "    df = df[:-100]\n",
    "    df_trade = df[df['action'] == 'T']\n",
    "    df_cancel = df[df['action'] == 'C']\n",
    "    df_add = df[df['action'] == 'A']\n",
    "    imb_trade = np.concatenate([imb_trade, df_trade['imbalance'].to_numpy()])\n",
    "    intensity_trade = np.concatenate([intensity_trade, df_trade['time_diff'].to_numpy()])\n",
    "    imb_add = np.concatenate([imb_add, df_add['imbalance'].to_numpy()])\n",
    "    intensity_add = np.concatenate([intensity_add, df_add['time_diff'].to_numpy()])\n",
    "    imb_cancel = np.concatenate([imb_cancel, df_cancel['imbalance'].to_numpy()])\n",
    "    intensity_cancel = np.concatenate([intensity_cancel, df_cancel['time_diff'].to_numpy()])\n",
    "    \n",
    "imb_tot = [imb_trade,imb_add,imb_cancel]\n",
    "intensity_tot = [1/np.array(intensity_trade),1/np.array(intensity_add),1/np.array(intensity_cancel)]\n",
    "\n",
    "print(f\"A quel point c'est long: {len(imb_trade)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu_intensity_respec(imb_tot, intensity_tot, i , string, group_size, bound = 0.9):\n",
    "    indices_trie = np.argsort(imb_tot[i])\n",
    "    imb_trie = imb_tot[i][indices_trie]\n",
    "    intensity_trie = intensity_tot[i][indices_trie]\n",
    "    mask = (imb_trie >= -bound) & (imb_trie <= bound)\n",
    "    imb_trie = imb_trie[mask]\n",
    "    intensity_trie = intensity_trie[mask]\n",
    "    imb_trie_groups = [imb_trie[i:i + group_size] for i in range(0, len(imb_trie), group_size)]\n",
    "    intensity_trie_groups = [intensity_trie[i:i + group_size] for i in range(0, len(intensity_trie), group_size)]\n",
    "    imb_trie_means = np.array([np.mean(group) for group in imb_trie_groups])\n",
    "    intensity_trie_means = np.array([np.mean(group) for group in intensity_trie_groups])\n",
    "    intensity_trie_std = np.array([np.std(group)/np.sqrt(len(group)) for group in intensity_trie_groups])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=imb_trie_means,y=intensity_trie_means + 1.96 * intensity_trie_std,mode='lines',line=dict(width=0),name='Upper Bound',showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=imb_trie_means,y=intensity_trie_means - 1.96 * intensity_trie_std,mode='lines',line=dict(width=0),fill='tonexty',fillcolor='blue',name='Intervalle de confiance à 95%',showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=imb_trie_means,y=intensity_trie_means,mode='lines',name='intensity',line=dict(color='red'),showlegend=True))\n",
    "    fig.update_layout(title=f\"Intensity des {string} en fonction de l'imbalance\",xaxis_title='imbalance',yaxis_title='Intensity',showlegend=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_intensity_respec(imb_tot, intensity_tot, 0 , 'trades', 120000)\n",
    "visu_intensity_respec(imb_tot, intensity_tot, 1 , 'add', 1000000)\n",
    "visu_intensity_respec(imb_tot, intensity_tot, 2 , 'cancel', 900000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul Intensités par average event size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dico_queue_size(sizes, dic):\n",
    "    for i in range (len(sizes)):\n",
    "        if sizes[i] not in dic:\n",
    "            dic[sizes[i]] = [[], [], []]\n",
    "    return dic\n",
    "\n",
    "def compute_means(dico):\n",
    "    sums = 0\n",
    "    means = 0\n",
    "    keys = np.array(list(dico.keys()))\n",
    "    for i in range (len(keys)):\n",
    "        means = means+keys[i]*len(dico[keys[i]][0])+keys[i]*len(dico[keys[i]][1])+keys[i]*len(dico[keys[i]][2])\n",
    "        sums = sums+len(dico[keys[i]][0])+len(dico[keys[i]][1])+len(dico[keys[i]][2])\n",
    "    return means/sums\n",
    "\n",
    "def filtrage(dico, nombre_bins, threshold=100):\n",
    "    dico_p = dict(reversed(list(dico.items())))\n",
    "    keys = list(dico_p.keys())\n",
    "    i = 0\n",
    "    while len(dico_p[keys[i]][0])<threshold:\n",
    "        i += 1\n",
    "    values = np.linspace(0, keys[i], nombre_bins, endpoint=True)\n",
    "    keys = np.array(list(dico.keys()))\n",
    "    \n",
    "    real_dic = {}\n",
    "    for i in range (len(keys)):\n",
    "        real_k_index = np.argmin(np.abs(values-keys[i]))\n",
    "        real_k = values[real_k_index]\n",
    "        \n",
    "        if real_k not in real_dic:\n",
    "            real_dic[real_k] = [\n",
    "                np.array(dico[keys[i]][0]),\n",
    "                np.array(dico[keys[i]][1]),\n",
    "                np.array(dico[keys[i]][2])\n",
    "            ]\n",
    "        else:\n",
    "            real_dic[real_k] = [\n",
    "                np.concatenate([real_dic[real_k][0], dico[keys[i]][0]]),\n",
    "                np.concatenate([real_dic[real_k][1], dico[keys[i]][1]]),\n",
    "                np.concatenate([real_dic[real_k][2], dico[keys[i]][2]])\n",
    "            ]\n",
    "    return real_dic\n",
    "\n",
    "def remove_nan_from_dico(dico):\n",
    "    cleaned_dico = {}\n",
    "    for key, value_lists in dico.items():\n",
    "        cleaned_value_lists = []\n",
    "        for value_list in value_lists:\n",
    "            value_array = np.array(value_list)\n",
    "            cleaned_array = value_array[~np.isnan(value_array)]\n",
    "            cleaned_value_lists.append(cleaned_array.tolist())\n",
    "        cleaned_dico[key] = cleaned_value_lists\n",
    "    return cleaned_dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "average_event_size = []\n",
    "for f in tqdm(files_csv):\n",
    "    df = pd.read_csv(f)\n",
    "    df['time_diff'] = df['time_diff']*1.0 # pour le modif en float c'est un timedelta là\n",
    "    sizes = np.unique(np.array((np.unique(df['bid_sz_00'].to_numpy())).tolist() + (np.unique(df['ask_sz_00'].to_numpy())).tolist()))\n",
    "    sizes.sort()\n",
    "    dic = dico_queue_size(sizes, dic)  # Add, Cancel, Trade\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        average_event_size.append(row.size)\n",
    "        if row.side == 'A':\n",
    "            taille = row.ask_sz_00\n",
    "        elif row.side == 'B':\n",
    "            taille = row.bid_sz_00\n",
    "        if row.action == 'A':\n",
    "            dic[taille][0].append(row.time_diff)\n",
    "        elif row.action == 'C':\n",
    "            dic[taille][1].append(row.time_diff)\n",
    "        elif row.action == 'T':\n",
    "            dic[taille][2].append(row.time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Add = []\n",
    "Cancel = []\n",
    "Trade = []\n",
    "sizes_add = []\n",
    "sizes_cancel = []\n",
    "sizes_trade = []\n",
    "threshold = 100\n",
    "\n",
    "#dic = remove_nan_from_dico(dic)\n",
    "average_sizes = compute_means(dic)\n",
    "intensities = dict(sorted(dic.items()))\n",
    "intensities = filtrage(intensities, 30, threshold=1000)\n",
    "\n",
    "threshold_trade = 10000\n",
    "threshold = 1000\n",
    "\n",
    "quarter_add = []\n",
    "quarter_cancel = []\n",
    "quarter_trade = []\n",
    "\n",
    "for i in intensities:\n",
    "    tab = np.concatenate((intensities[i][0], intensities[i][1], intensities[i][2]))\n",
    "    if (len(intensities[i][0])>threshold):\n",
    "            Add.append(1/np.mean(tab)*len(intensities[i][0])/len(tab))\n",
    "            quarter_add.append(np.var(tab)*1/np.mean(tab)*len(intensities[i][0])/len(tab)*1/np.sqrt(len(tab)))\n",
    "            sizes_add.append(i)\n",
    "    if len(intensities[i][1])!=0:\n",
    "        if (len(intensities[i][1])>threshold):\n",
    "            Cancel.append(1/np.mean(tab)*len(intensities[i][1])/len(tab))\n",
    "            quarter_cancel.append(np.var(tab)*1/np.mean(tab)*len(intensities[i][1])/len(tab)*1/np.sqrt(len(tab)))\n",
    "            sizes_cancel.append(i)\n",
    "    if len(intensities[i][2])!=0:\n",
    "        if (len(intensities[i][2])>threshold_trade):\n",
    "            Trade.append(1/np.mean(tab)*len(intensities[i][2])/len(tab))\n",
    "            quarter_trade.append(np.var(tab)*1/np.mean(tab)*len(intensities[i][2])/len(tab)*1/np.sqrt(len(tab)))\n",
    "            sizes_trade.append(i)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sizes_add/np.mean(average_event_size),y=Add,mode='lines',name='Add',showlegend=True,line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=sizes_add/np.mean(average_event_size),y=np.array(Add)+1.96*np.array(quarter_add),mode='lines',name='Add Upper CI',line=dict(width=0),fill=None,showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=sizes_add/np.mean(average_event_size),y=np.array(Add)-1.96*np.array(quarter_add),mode='lines',name='Add Lower CI',fill='tonexty',line=dict(width=0),fillcolor='rgba(0, 0, 255, 0.2)',showlegend=False))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sizes_cancel/np.mean(average_event_size),y=Cancel,mode='lines',name='Cancel',showlegend=True,line=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=sizes_cancel/np.mean(average_event_size),y=np.array(Cancel)+1.96*np.array(quarter_cancel),mode='lines',name='Cancel Upper CI',line=dict(width=0),fill=None,showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=sizes_cancel/np.mean(average_event_size),y=np.array(Cancel)-1.96*np.array(quarter_cancel),mode='lines',name='Cancel Lower CI',fill='tonexty',line=dict(width=0),fillcolor='rgba(0, 255, 0, 0.2)',showlegend=False))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=sizes_trade/np.mean(average_event_size),y=Trade,mode='lines',name='Trade',showlegend=True,line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=sizes_trade/np.mean(average_event_size),y=np.array(Trade)+1.96*np.array(quarter_trade),mode='lines',name='Trade Upper CI',line=dict(width=0),fill=None,showlegend=False))\n",
    "fig.add_trace(go.Scatter(x=sizes_trade/np.mean(average_event_size),y=np.array(Trade)-1.96*np.array(quarter_trade),mode='lines',name='Trade Lower CI',fill='tonexty',line=dict(width=0),fillcolor='rgba(255, 0, 0, 0.2)',showlegend=False))\n",
    "\n",
    "fig.update_layout(title=\"Intensité par Queue size avec intervalles d'incertitude\",xaxis_title='Size (par Mean Event Size)',yaxis_title='Intensity (num par sec)',showlegend=True)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
